#!/usr/bin/env python3
"""
æµ‹è¯•ä¿®æ”¹åçš„å¿…é¡»å…³é”®è¯é€»è¾‘
"""
import sys
import os

sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from arxiv_core import PaperRanker


def test_new_required_keywords_logic():
    """æµ‹è¯•æ–°çš„å¿…é¡»å…³é”®è¯é€»è¾‘ï¼ˆæ‰€æœ‰å…³é”®è¯éƒ½å¿…é¡»åŒ¹é…ï¼‰"""
    print("ğŸ§ª æµ‹è¯•æ–°çš„å¿…é¡»å…³é”®è¯é€»è¾‘")
    print("=" * 50)

    # åˆ›å»ºæœç´¢å™¨å®ä¾‹
    ranker = PaperRanker()

    # æ¨¡æ‹Ÿé…ç½® - æ‰€æœ‰å…³é”®è¯éƒ½å¿…é¡»åŒ¹é…
    required_keywords_config = {
        'enabled': True,
        'fuzzy_match': True,
        'similarity_threshold': 0.8,
        'keywords': [
            'humanoid',  # å¿…é¡»åŒ…å«
            'imitation',  # å¿…é¡»åŒ…å«
        ],
    }

    # æµ‹è¯•ç”¨ä¾‹
    test_cases = [
        {
            'title': 'Humanoid Robot Imitation Learning',
            'abstract': 'This paper presents a humanoid robot system that learns through imitation.',
            'expected_pass': True,
            'reason': 'åŒ…å«humanoidå’Œimitationï¼Œåº”è¯¥é€šè¿‡',
        },
        {
            'title': 'Humanoid Robot Walking',
            'abstract': 'This work focuses on humanoid robot walking algorithms.',
            'expected_pass': False,
            'reason': 'åªåŒ…å«humanoidï¼Œç¼ºå°‘imitationï¼Œåº”è¯¥è¢«è¿‡æ»¤',
        },
        {
            'title': 'Imitation Learning for Manipulation',
            'abstract': 'We develop imitation learning methods for robot manipulation tasks.',
            'expected_pass': False,
            'reason': 'åªåŒ…å«imitationï¼Œç¼ºå°‘humanoidï¼Œåº”è¯¥è¢«è¿‡æ»¤',
        },
        {
            'title': 'Deep Learning in Computer Vision',
            'abstract': 'We propose a new deep learning architecture for computer vision tasks.',
            'expected_pass': False,
            'reason': 'ä¸åŒ…å«ä»»ä½•å¿…é¡»å…³é”®è¯ï¼Œåº”è¯¥è¢«è¿‡æ»¤',
        },
        {
            'title': 'Humanoid Imitation of Human Movements',
            'abstract': 'This research explores how humanoid robots can imitate complex human movements.',
            'expected_pass': True,
            'reason': 'åŒ…å«humanoidå’Œimitationï¼ˆå˜ä½“ï¼‰ï¼Œåº”è¯¥é€šè¿‡',
        },
    ]

    # æ‰§è¡Œæµ‹è¯•
    all_passed = True
    for i, test_case in enumerate(test_cases, 1):
        print(f"\nğŸ“ æµ‹è¯•ç”¨ä¾‹ {i}: {test_case['title']}")
        print(f"æ‘˜è¦: {test_case['abstract']}")
        print(f"æœŸæœ›ç»“æœ: {'âœ… é€šè¿‡' if test_case['expected_pass'] else 'âŒ è¢«è¿‡æ»¤'}")
        print(f"åŸå› : {test_case['reason']}")

        # åˆ›å»ºæ¨¡æ‹Ÿè®ºæ–‡å­—å…¸
        mock_paper = {
            'title': test_case['title'],
            'summary': test_case['abstract'],
            'categories': [],
            'authors_str': '',
        }

        # æ£€æŸ¥å¿…é¡»å…³é”®è¯
        matched, matched_keywords = ranker.check_required_keywords(mock_paper, required_keywords_config)

        print(f"å®é™…ç»“æœ: {'âœ… é€šè¿‡' if matched else 'âŒ è¢«è¿‡æ»¤'}")
        print(f"åŒ¹é…åˆ°çš„å…³é”®è¯: {matched_keywords}")

        # éªŒè¯ç»“æœ
        if matched == test_case['expected_pass']:
            print(f"æµ‹è¯•ç»“æœ: âœ… æ­£ç¡®")
        else:
            print(f"æµ‹è¯•ç»“æœ: âŒ é”™è¯¯")
            all_passed = False

    print("\n" + "=" * 50)
    print("ğŸ¯ æ–°é€»è¾‘è¯´æ˜:")
    print("- æ‰€æœ‰é…ç½®çš„å…³é”®è¯éƒ½å¿…é¡»åŒ¹é…ï¼ˆANDé€»è¾‘ï¼‰")
    print("- æ”¯æŒæ¨¡ç³ŠåŒ¹é…å’Œè¯å½¢å˜åŒ–")
    print("- è¿”å›çš„åŒ¹é…å…³é”®è¯æ˜¯é…ç½®ä¸­çš„åŸå§‹å…³é”®è¯")
    print("- ä¸æ˜¾ç¤ºå…·ä½“åŒ¹é…åˆ°çš„è¯æ±‡æˆ–æ¨¡ç³ŠåŒ¹é…æ ‡è®°")

    print(f"\nğŸ‰ æ€»ä½“æµ‹è¯•ç»“æœ: {'âœ… å…¨éƒ¨é€šè¿‡' if all_passed else 'âŒ æœ‰å¤±è´¥ç”¨ä¾‹'}")


if __name__ == "__main__":
    test_new_required_keywords_logic()
