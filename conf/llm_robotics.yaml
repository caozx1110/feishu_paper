defaults:
  - default
  - _self_
user_profile:
  name: LLMæœºå™¨äººç ”ç©¶å‘˜
  description: ä¸“æ³¨äºå¤§è¯­è¨€æ¨¡å‹ä¸æœºå™¨äººæŠ€æœ¯ç»“åˆçš„ç ”ç©¶
  research_area: llm_robotics

search:
  field: robotics
  days: 14
  max_results: 500
  max_display: 10
  min_score: 0.3

interest_keywords:
  # ğŸ¯ æ ¸å¿ƒæ¦‚å¿µ (é«˜æƒé‡)
  - "# ğŸ¯ æ ¸å¿ƒæ¦‚å¿µ (é«˜æƒé‡)"
  - vla
  - vision language action
  - llm robot
  - embodied ai
  - rt-1
  - rt-2
  - rt-x
  - palm-e
  - saycan
  - cliport
  - peract
  - vima
  - flamingo robot
  - roboflamingo

  # ğŸ”§ æ‰©å±•æ¦‚å¿µ (ä¸­æƒé‡)
  - "# ğŸ”§ æ‰©å±•æ¦‚å¿µ (ä¸­æƒé‡)"
  - large language model robot
  - language model robotics
  - foundation model robotics
  - multimodal robot
  - embodied intelligence
  - grounded language
  - robot language model
  - language grounding
  - instruction following
  - natural language robotics
  - vision transformer robot
  - language to action
  - text to action
  - instruction to action
  - robot foundation model
  - vlm robot
  - visual language model
  - code generation robot
  - zero-shot robot
  - few-shot robot
  - in-context learning robot
  - chain of thought robot
  - reasoning robot

exclude_keywords:
  # æ’é™¤é LLM + æœºå™¨äººç ”ç©¶æ–¹å‘
  - medical robot
  - surgical robot
  - rehabilitation robot
  - therapy robot
  - drug discovery
  - pharmaceutical
  - clinical
  - biomedical
  - healthcare robot
  - pure mathematics
  - theoretical physics
  - quantum
  - cryptography
  - social robot
  - human-robot interaction only
  - simulation-only studies
  - pure perception
  - pure locomotion

description: LLMä¸æœºå™¨äººç»“åˆé¢†åŸŸé…ç½®ï¼Œä¸“æ³¨äºVLAã€å¤šæ¨¡æ€æœºå™¨äººå’Œè¯­è¨€å¼•å¯¼çš„æœºå™¨äººæŠ€æœ¯ [ç²¾ç‚¼å…³é”®è¯ç»“æ„ï¼Œæ ¸å¿ƒä¼˜å…ˆ]
