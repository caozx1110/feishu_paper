#!/usr/bin/env python3
"""
åŸºäº Hydra çš„ ArXiv è®ºæ–‡é‡‡é›†å·¥å…·
æ”¯æŒçµæ´»çš„é…ç½®ç®¡ç†å’Œä¸“ä¸šé¢†åŸŸå…³é”®è¯
"""

import sys
import os
from datetime import datetime
import hydra
from hydra.core.hydra_config import HydraConfig
from omegaconf import DictConfig, OmegaConf
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from arxiv_core import ArxivAPI, PaperRanker
from paper_display import PaperDisplayer


def load_keywords_from_config(cfg: DictConfig):
    """ä»é…ç½®ä¸­åŠ è½½å…³é”®è¯"""
    # æ–°çš„æ‰©å±•é…ç½®ç»“æ„ - ä¼˜å…ˆä½¿ç”¨å…³é”®è¯é…ç½®ä¸­çš„è®¾ç½®
    if hasattr(cfg, 'keywords'):
        # ä¼ ç»Ÿç»“æ„æ”¯æŒ
        raw_interest_keywords = cfg.keywords.get('interest_keywords', [])
        raw_exclude_keywords = cfg.keywords.get('exclude_keywords', [])
    else:
        # ç›´æ¥ä»æ ¹çº§åˆ«è·å–
        raw_interest_keywords = cfg.get('interest_keywords', [])
        raw_exclude_keywords = cfg.get('exclude_keywords', [])

    # è½¬æ¢ä¸ºPythonåˆ—è¡¨ï¼ˆå¦‚æœæ˜¯DictConfigï¼‰
    if hasattr(raw_interest_keywords, '_content'):
        raw_interest_keywords = list(raw_interest_keywords)
    if hasattr(raw_exclude_keywords, '_content'):
        raw_exclude_keywords = list(raw_exclude_keywords)

    # è¿‡æ»¤æ‰æ³¨é‡Šè¡Œå’Œç©ºè¡Œï¼ˆç”¨äºå®é™…åŒ¹é…ï¼‰
    interest_keywords = _filter_keywords(raw_interest_keywords)
    exclude_keywords = _filter_keywords(raw_exclude_keywords)

    return interest_keywords, exclude_keywords, raw_interest_keywords


def _filter_keywords(keywords):
    """è¿‡æ»¤å…³é”®è¯åˆ—è¡¨ï¼Œç§»é™¤æ³¨é‡Šè¡Œå’Œç©ºè¡Œ"""
    if not keywords:
        return []
    
    filtered = []
    for keyword in keywords:
        # è·³è¿‡ç©ºå­—ç¬¦ä¸²
        if not keyword or not keyword.strip():
            continue
        
        # è·³è¿‡æ³¨é‡Šè¡Œï¼ˆä»¥ # å¼€å¤´ï¼‰
        if keyword.strip().startswith('#'):
            continue
            
        # ä¿ç•™æœ‰æ•ˆå…³é”®è¯
        filtered.append(keyword.strip())
    
    return filtered


def merge_configs(global_cfg: DictConfig, keyword_cfg: DictConfig) -> DictConfig:
    """åˆå¹¶å…¨å±€é…ç½®å’Œå…³é”®è¯é…ç½®ï¼Œå…³é”®è¯é…ç½®ä¼˜å…ˆ"""
    merged_cfg = OmegaConf.merge(global_cfg, keyword_cfg)
    
    # å¦‚æœå…³é”®è¯é…ç½®æœ‰search_configï¼Œåˆ™è¦†ç›–å…¨å±€searché…ç½®
    if hasattr(keyword_cfg, 'search_config'):
        merged_cfg.search = OmegaConf.merge(merged_cfg.search, keyword_cfg.search_config)
    
    # å¦‚æœå…³é”®è¯é…ç½®æœ‰å…¶ä»–_configåç¼€çš„é…ç½®ï¼Œåˆ™è¦†ç›–å¯¹åº”çš„å…¨å±€é…ç½®
    config_mappings = {
        'intelligent_matching_config': 'intelligent_matching',
        'download_config': 'download',
        'display_config': 'display',
        'output_config': 'output'
    }
    
    for config_key, global_key in config_mappings.items():
        if hasattr(keyword_cfg, config_key):
            if not hasattr(merged_cfg, global_key):
                merged_cfg[global_key] = {}
            merged_cfg[global_key] = OmegaConf.merge(
                merged_cfg[global_key], 
                keyword_cfg[config_key]
            )
    
    return merged_cfg


def print_config_info(cfg: DictConfig):
    """æ‰“å°é…ç½®ä¿¡æ¯"""
    print("ğŸ“š ArXiv è®ºæ–‡é‡‡é›†å·¥å…· - æ‰©å±•é…ç½®ç‰ˆ")
    print(f"ğŸ•’ {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}")
    print("=" * 70)

    # æ˜¾ç¤ºç”¨æˆ·ä¿¡æ¯ï¼ˆæ–°çš„æ‰©å±•é…ç½®ç»“æ„ï¼‰
    if hasattr(cfg, 'user_profile'):
        print(f"ğŸ‘¤ ç”¨æˆ·: {cfg.user_profile.get('name', 'Unknown')}")
        print(f"ğŸ“ æè¿°: {cfg.user_profile.get('description', 'No description')}")
        print(f"ğŸ”¬ ç ”ç©¶é¢†åŸŸ: {cfg.user_profile.get('research_area', 'general')}")
    elif hasattr(cfg, 'keywords') and hasattr(cfg.keywords, 'description'):
        # å‘åå…¼å®¹ä¼ ç»Ÿç»“æ„
        keywords_name = cfg.defaults[0].keywords if hasattr(cfg, 'defaults') else "unknown"
        print(f"ğŸ“‹ å½“å‰é…ç½®: {keywords_name}")
        print(f"ğŸ“ é…ç½®æè¿°: {cfg.keywords.description}")
    else:
        # æœ€åŸºç¡€çš„å…¼å®¹æ€§
        keywords_name = cfg.defaults[0].keywords if hasattr(cfg, 'defaults') else "unknown"
        print(f"ï¿½ å½“å‰é…ç½®: {keywords_name}")

    # æ˜¾ç¤ºå…³é”®è¯
    interest_keywords, exclude_keywords, raw_interest_keywords = load_keywords_from_config(cfg)

    if interest_keywords:
        print(f"\nğŸ¯ å…³æ³¨è¯æ¡ ({len(interest_keywords)}ä¸ª):")
        print(f"   {' > '.join(interest_keywords[:5])}{'...' if len(interest_keywords) > 5 else ''}")

    if exclude_keywords:
        print(f"ğŸš« æ’é™¤è¯æ¡ ({len(exclude_keywords)}ä¸ª):")
        print(f"   {', '.join(exclude_keywords[:5])}{'...' if len(exclude_keywords) > 5 else ''}")

    print(f"âš™ï¸  æœç´¢å‚æ•°:")
    search_cfg = cfg.get('search', {})
    print(f"   å¤©æ•°: {search_cfg.get('days', 'N/A')}, æœ€å¤§ç»“æœ: {search_cfg.get('max_results', 'N/A')}")
    print(f"   é¢†åŸŸ: {search_cfg.get('field', 'N/A')}, æœ€å°è¯„åˆ†: {search_cfg.get('min_score', 'N/A')}")

    # æ˜¾ç¤ºæ™ºèƒ½åŒ¹é…é…ç½®
    intelligent_cfg = cfg.get('intelligent_matching', {})
    if intelligent_cfg.get('enabled', False):
        print(f"ğŸ§  æ™ºèƒ½åŒ¹é…: å¯ç”¨")
        weights = intelligent_cfg.get('score_weights', {})
        print(f"   è¯„åˆ†æƒé‡: åŸºç¡€({weights.get('base', 0)}) è¯­ä¹‰({weights.get('semantic', 0)}) æ–°é¢–æ€§({weights.get('novelty', 0)})")
    else:
        print(f"ğŸ§  æ™ºèƒ½åŒ¹é…: å…³é—­")

    # æ˜¾ç¤ºä¸‹è½½é…ç½®
    download_cfg = cfg.get('download', {})
    if download_cfg.get('enabled', False):
        print(f"ğŸ“¥ PDFä¸‹è½½: å¯ç”¨ (æœ€å¤š{download_cfg.get('max_downloads', 0)}ç¯‡)")
    else:
        print(f"ğŸ“¥ PDFä¸‹è½½: å…³é—­")

    print("=" * 70)


@hydra.main(version_base=None, config_path="conf", config_name="default")
def main(cfg: DictConfig) -> None:
    """ä¸»å‡½æ•°"""

    # æ£€æŸ¥æ˜¯å¦æ˜¯æ‰©å±•é…ç½®ç»“æ„ï¼Œå¦‚æœæ˜¯åˆ™è¿›è¡Œé…ç½®åˆå¹¶
    if hasattr(cfg, 'search_config') or hasattr(cfg, 'user_profile'):
        # åˆ›å»ºåŸºç¡€é…ç½®ç»“æ„
        base_cfg = OmegaConf.create({
            'search': {
                'days': 7,
                'max_results': 300,
                'max_display': 10,
                'min_score': 0.1,
                'field': 'all'
            },
            'download': {
                'enabled': False,
                'max_downloads': 10,
                'download_dir': 'downloads',
                'create_metadata': True,
                'create_index': True,
                'force_download': False
            },
            'intelligent_matching': {
                'enabled': False,
                'score_weights': {
                    'base': 1.0,
                    'semantic': 0.3,
                    'author': 0.2,
                    'novelty': 0.4,
                    'citation': 0.3
                },
                'fuzzy_threshold': 0.8,
                'time_decay_days': 30
            },
            'display': {
                'show_ranking': True,
                'show_scores': True,
                'show_breakdown': False,
                'stats': True
            },
            'output': {
                'save': True,
                'save_keywords': False,
                'include_scores': True,
                'format': 'markdown'
            }
        })
        final_cfg = merge_configs(base_cfg, cfg)
    else:
        # ä¼ ç»Ÿé…ç½®ç»“æ„ï¼Œç›´æ¥ä½¿ç”¨
        final_cfg = cfg

    # åˆå§‹åŒ–ç»„ä»¶
    download_dir = final_cfg.get('download', {}).get('download_dir', 'downloads')
    arxiv_api = ArxivAPI(download_dir=download_dir)
    paper_ranker = PaperRanker()
    displayer = PaperDisplayer()

    # æ‰“å°é…ç½®ä¿¡æ¯
    print_config_info(final_cfg)

    # åŠ è½½å…³é”®è¯
    interest_keywords, exclude_keywords, raw_interest_keywords = load_keywords_from_config(final_cfg)

    # è·å–è®ºæ–‡ - ä½¿ç”¨æ–°çš„å­—æ®µç±»å‹
    search_cfg = final_cfg.get('search', {})
    papers = arxiv_api.get_recent_papers(
        days=search_cfg.get('days', 7), 
        max_results=search_cfg.get('max_results', 300), 
        field_type=search_cfg.get('field', 'all')
    )

    if not papers:
        print("âŒ æœªæ‰¾åˆ°ç›¸å…³è®ºæ–‡")
        return

    # é¢†åŸŸç­›é€‰
    field_names = {'ai': 'äººå·¥æ™ºèƒ½/æœºå™¨å­¦ä¹ ', 'robotics': 'æœºå™¨äººå­¦', 'cv': 'è®¡ç®—æœºè§†è§‰', 'nlp': 'è‡ªç„¶è¯­è¨€å¤„ç†'}
    field = search_cfg.get('field', 'all')

    if field != 'all':
        field_name = field_names.get(field, field)
        print(f"\nğŸ¯ {field_name} é¢†åŸŸç­›é€‰ç»“æœ: {len(papers)} ç¯‡")
    else:
        field_name = "å…¨éƒ¨"

    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    display_cfg = final_cfg.get('display', {})
    if display_cfg.get('stats', True):
        displayer.display_hot_categories(papers)

    # æ™ºèƒ½æ’åºå¤„ç†
    if interest_keywords or exclude_keywords:
        # æ£€æŸ¥æ˜¯å¦å¯ç”¨æ™ºèƒ½åŒ¹é…
        intelligent_cfg = final_cfg.get('intelligent_matching', {})
        use_intelligent = intelligent_cfg.get('enabled', False)
        score_weights = None

        if use_intelligent:
            # è·å–æ™ºèƒ½åŒ¹é…é…ç½®
            score_weights = dict(intelligent_cfg.get('score_weights', {}))
            print(f"\nğŸ§  ä½¿ç”¨æ™ºèƒ½åŒ¹é…æ¨¡å¼")
        else:
            print(f"\nğŸ” ä½¿ç”¨åŸºç¡€åŒ¹é…æ¨¡å¼")

        ranked_papers, excluded_papers, score_stats = paper_ranker.filter_and_rank_papers(
            papers,
            interest_keywords,
            exclude_keywords,
            search_cfg.get('min_score', 0.1),
            use_advanced_scoring=use_intelligent,
            score_weights=score_weights,
            raw_interest_keywords=raw_interest_keywords,
        )

        if score_stats:
            if use_intelligent:
                displayer.display_advanced_ranking_stats(ranked_papers, score_stats)
            else:
                displayer.display_ranking_stats(score_stats, excluded_papers)

        if ranked_papers:
            # PDFä¸‹è½½å¤„ç†
            download_cfg = final_cfg.get('download', {})
            if download_cfg.get('enabled', False) and ranked_papers:
                print(f"\nğŸ“¥ å¼€å§‹ä¸‹è½½PDFæ–‡ä»¶...")
                download_stats = arxiv_api.batch_download_pdfs(
                    ranked_papers[: download_cfg.get('max_downloads', 10)],
                    max_downloads=download_cfg.get('max_downloads', 10),
                    create_index=download_cfg.get('create_index', True),
                )

                print(
                    f"ğŸ“Š ä¸‹è½½ç»Ÿè®¡: æˆåŠŸ {download_stats['downloaded']}, "
                    f"è·³è¿‡ {download_stats['skipped']}, å¤±è´¥ {download_stats['failed']}"
                )

                if download_stats['failed_papers']:
                    print("âŒ ä¸‹è½½å¤±è´¥çš„è®ºæ–‡:")
                    for failed in download_stats['failed_papers']:
                        print(f"   - {failed['title'][:50]}... ({failed['error']})")

            display_cfg = final_cfg.get('display', {})
            if display_cfg.get('show_ranking', True):
                if use_intelligent:
                    show_breakdown = display_cfg.get('show_breakdown', False)
                    displayer.display_advanced_ranked_papers(
                        ranked_papers, search_cfg.get('max_display', 10), show_breakdown=show_breakdown
                    )
                else:
                    displayer.display_ranked_papers(
                        ranked_papers, search_cfg.get('max_display', 10), show_scores=display_cfg.get('show_scores', True)
                    )

            # ä¿å­˜æŠ¥å‘Š
            output_cfg = final_cfg.get('output', {})
            if output_cfg.get('save', True):
                # è·å–é…ç½®æ–‡ä»¶åå’Œç ”ç©¶é¢†åŸŸå
                try:
                    hydra_cfg = HydraConfig.get()
                    actual_config_name = hydra_cfg.job.config_name
                except:
                    actual_config_name = "unknown"
                
                # è·å–ç ”ç©¶é¢†åŸŸåæˆ–ç”¨æˆ·å
                research_area = ""
                if hasattr(final_cfg, 'user_profile'):
                    research_area = final_cfg.user_profile.get('research_area', '')
                elif hasattr(final_cfg, 'defaults'):
                    research_area = final_cfg.defaults[0].keywords if hasattr(final_cfg.defaults[0], 'keywords') else ''
                
                output_format = output_cfg.get('format', 'txt')

                if output_format == 'markdown':
                    displayer.save_papers_report_markdown(
                        ranked_papers,
                        field_name,
                        search_cfg.get('days', 7),
                        include_scores=output_cfg.get('include_scores', True),
                        config_name=actual_config_name,
                        research_area=research_area,
                    )
                else:
                    displayer.save_papers_report(
                        ranked_papers,
                        field_name,
                        search_cfg.get('days', 7),
                        include_scores=output_cfg.get('include_scores', True),
                        config_name=actual_config_name,
                        research_area=research_area,
                    )
        else:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„ç›¸å…³è®ºæ–‡")
    else:
        # å¸¸è§„æ˜¾ç¤º
        displayer.display_papers_detailed(papers, search_cfg.get('max_display', 10))

        # PDFä¸‹è½½å¤„ç†ï¼ˆæ— å…³é”®è¯ç­›é€‰ï¼‰
        download_cfg = final_cfg.get('download', {})
        if download_cfg.get('enabled', False) and papers:
            print(f"\nğŸ“¥ å¼€å§‹ä¸‹è½½PDFæ–‡ä»¶...")
            download_stats = arxiv_api.batch_download_pdfs(
                papers[: download_cfg.get('max_downloads', 10)],
                max_downloads=download_cfg.get('max_downloads', 10),
                create_index=download_cfg.get('create_index', True),
            )

            print(
                f"ğŸ“Š ä¸‹è½½ç»Ÿè®¡: æˆåŠŸ {download_stats['downloaded']}, "
                f"è·³è¿‡ {download_stats['skipped']}, å¤±è´¥ {download_stats['failed']}"
            )

        if final_cfg.output.save:
            # è·å–é…ç½®æ–‡ä»¶åå’Œç ”ç©¶é¢†åŸŸå
            try:
                hydra_cfg = HydraConfig.get()
                actual_config_name = hydra_cfg.job.config_name
            except:
                actual_config_name = "unknown"
            
            # è·å–ç ”ç©¶é¢†åŸŸåæˆ–ç”¨æˆ·å
            research_area = ""
            if hasattr(final_cfg, 'user_profile'):
                research_area = final_cfg.user_profile.get('research_area', '')
            elif hasattr(final_cfg, 'defaults'):
                research_area = final_cfg.defaults[0].keywords if hasattr(final_cfg.defaults[0], 'keywords') else ''
                
            output_format = final_cfg.output.get('format', 'txt')

            if output_format == 'markdown':
                displayer.save_papers_report_markdown(
                    papers, field_name, final_cfg.search.days, include_scores=False, 
                    config_name=actual_config_name, research_area=research_area
                )
            else:
                displayer.save_papers_report(
                    papers, field_name, final_cfg.search.days, include_scores=False, 
                    config_name=actual_config_name, research_area=research_area
                )

    print(f"\nâœ… é‡‡é›†å®Œæˆï¼")


if __name__ == "__main__":
    main()
