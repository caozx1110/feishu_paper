"""
é£ä¹¦æ•°æ®åŒæ­¥ç®¡ç†å™¨

æ•´åˆå¤šç»´è¡¨æ ¼å’ŒèŠå¤©é€šçŸ¥åŠŸèƒ½ï¼Œæä¾›ç»Ÿä¸€çš„æ•°æ®åŒæ­¥æ¥å£ã€‚
"""

import logging
from typing import Dict, List, Any, Optional
from datetime import datetime
from .config import FeishuConfig
from .bitable import BitableManager
from .notification import ChatNotifier, ChatNotificationConfig
from .table_manager import ConfigBasedTableManager

logger = logging.getLogger(__name__)


class SyncManager:
    """é£ä¹¦æ•°æ®åŒæ­¥ç®¡ç†å™¨"""

    def __init__(self, config: FeishuConfig, notification_config: ChatNotificationConfig = None):
        """
        åˆå§‹åŒ–åŒæ­¥ç®¡ç†å™¨

        Args:
            config: é£ä¹¦é…ç½®å¯¹è±¡
            notification_config: é€šçŸ¥é…ç½®
        """
        self.config = config
        self.bitable_manager = BitableManager(config)
        self.chat_notifier = ChatNotifier(config, notification_config)

        logger.info("ğŸ”„ é£ä¹¦åŒæ­¥ç®¡ç†å™¨å·²åˆå§‹åŒ–")

    def refresh_token_before_sync(self) -> bool:
        """åœ¨åŒæ­¥å‰åˆ·æ–°tokenä»¥ç¡®ä¿æœ‰æ•ˆæ€§

        Returns:
            bool: æ˜¯å¦æˆåŠŸåˆ·æ–°token
        """
        try:
            logger.info("ğŸ”„ æ£€æŸ¥å¹¶åˆ·æ–°é£ä¹¦è®¿é—®token...")
            # å¼ºåˆ¶è·å–æ–°çš„token
            new_token = self.bitable_manager.connector.get_tenant_access_token()
            if new_token:
                logger.info(f"âœ… Tokenåˆ·æ–°æˆåŠŸ: {new_token[:20]}...")
                return True
            else:
                logger.error("âŒ Tokenåˆ·æ–°å¤±è´¥")
                return False
        except Exception as e:
            logger.error(f"âŒ Tokenåˆ·æ–°å¼‚å¸¸: {e}")
            return False

    def sync_papers_with_config(
        self,
        papers: List[Dict[str, Any]],
        cfg,
        enable_notification: bool = True,
    ) -> Dict[str, Any]:
        """æ ¹æ®é…ç½®æ–‡ä»¶åŒæ­¥è®ºæ–‡åˆ°å¯¹åº”è¡¨æ ¼

        Args:
            papers: è®ºæ–‡åˆ—è¡¨
            cfg: Hydraé…ç½®å¯¹è±¡
            enable_notification: æ˜¯å¦å¯ç”¨é€šçŸ¥

        Returns:
            åŒæ­¥ç»“æœç»Ÿè®¡
        """
        logger.info(f"ğŸš€ å¼€å§‹æ ¹æ®é…ç½®åŒæ­¥è®ºæ–‡æ•°æ®ï¼Œå…± {len(papers)} ç¯‡è®ºæ–‡")

        # åœ¨åŒæ­¥å‰åˆ·æ–°tokenä»¥ç¡®ä¿æœ‰æ•ˆæ€§
        if not self.refresh_token_before_sync():
            logger.error("âŒ Tokenåˆ·æ–°å¤±è´¥ï¼ŒåŒæ­¥ç»ˆæ­¢")
            return {"success": False, "error": "Tokenåˆ·æ–°å¤±è´¥"}

        # åˆ›å»ºè¡¨æ ¼ç®¡ç†å™¨
        table_manager = ConfigBasedTableManager(self.config)

        # æ ¹æ®é…ç½®åˆ›å»ºè¡¨æ ¼
        table_mapping = table_manager.create_tables_from_config(cfg)

        if not table_mapping:
            logger.warning("âš ï¸ æ²¡æœ‰åˆ›å»ºä»»ä½•è¡¨æ ¼ï¼ŒåŒæ­¥ç»ˆæ­¢")
            return {"synced_count": 0, "total_count": 0, "tables": {}}

        # ç”Ÿæˆè¡¨æ ¼é“¾æ¥
        table_links = table_manager.get_table_links(table_mapping)

        # è·å–ç ”ç©¶é¢†åŸŸä¿¡æ¯
        user_profile = cfg.get("user_profile", {})
        research_area = user_profile.get("research_area", "general")
        table_id = list(table_mapping.values())[0]  # è·å–ç¬¬ä¸€ä¸ª(ä¹Ÿæ˜¯å”¯ä¸€çš„)è¡¨æ ¼ID

        # åŒæ­¥è®ºæ–‡æ•°æ®
        sync_result = self._sync_papers_to_table(papers, table_id, research_area)

        # æ„å»ºç»Ÿè®¡ä¿¡æ¯
        sync_stats = {
            research_area: {
                "table_id": table_id,
                "table_name": sync_result.get("table_name", f"{research_area}è®ºæ–‡è¡¨"),
                "new_count": sync_result.get("synced_count", 0),
                "total_count": sync_result.get("total_count", 0),
            }
        }

        total_synced = sync_result.get("synced_count", 0)
        total_papers = sync_result.get("total_count", 0)

        logger.info(f"ğŸ“Š åŒæ­¥å®Œæˆï¼šæ–°å¢ {total_synced} ç¯‡ï¼Œæ€»è®¡ {total_papers} ç¯‡")

        # å‘é€é€šçŸ¥
        if enable_notification and total_synced > 0:
            logger.info("ğŸ“¢ å‘é€ç¾¤èŠé€šçŸ¥...")
            # æ„å»ºæŒ‰é¢†åŸŸåˆ†ç»„çš„è®ºæ–‡æ•°æ®è¿›è¡Œæ¨è
            papers_by_field = {research_area: papers}
            self.chat_notifier.notify_paper_updates(sync_stats, papers_by_field, table_links)

        return {
            "synced_count": total_synced,
            "total_count": total_papers,
            "tables": sync_stats,
            "table_links": table_links,
        }

    def _sync_papers_to_table(
        self,
        papers: List[Dict[str, Any]],
        table_id: str,
        research_area: str,
        batch_size: int = 20,
    ) -> Dict[str, Any]:
        """åŒæ­¥è®ºæ–‡åˆ°æŒ‡å®šè¡¨æ ¼

        Args:
            papers: è®ºæ–‡åˆ—è¡¨
            table_id: ç›®æ ‡è¡¨æ ¼ID
            research_area: ç ”ç©¶é¢†åŸŸ
            batch_size: æ‰¹é‡å¤§å°

        Returns:
            åŒæ­¥ç»“æœ
        """
        if not papers:
            return {"synced_count": 0, "total_count": 0, "table_name": f"{research_area}è®ºæ–‡è¡¨"}

        # è·å–ç°æœ‰è®°å½•ï¼Œé¿å…é‡å¤
        existing_records = self.bitable_manager.get_all_records(table_id)
        existing_arxiv_ids = set()

        for record in existing_records:
            fields = record.get("fields", {})
            arxiv_id_field = fields.get("ArXiv ID", "")

            if isinstance(arxiv_id_field, dict):
                arxiv_id = arxiv_id_field.get("text", "")
            else:
                arxiv_id = str(arxiv_id_field) if arxiv_id_field else ""

            if arxiv_id:
                existing_arxiv_ids.add(arxiv_id)

        # å‡†å¤‡æ–°è®ºæ–‡æ•°æ®
        new_papers_data = []
        new_papers_original = []  # ä¿å­˜åŸå§‹è®ºæ–‡æ•°æ®ç”¨äºæ¨è
        for paper in papers:
            formatted_data = self._format_paper_for_sync(paper, research_area)
            if formatted_data:
                arxiv_id = paper.get("arxiv_id", "")
                if arxiv_id not in existing_arxiv_ids:
                    new_papers_data.append(formatted_data)
                    new_papers_original.append(paper)  # ä¿å­˜åŸå§‹è®ºæ–‡æ•°æ®

        logger.info(f"ğŸ“ {research_area}ï¼šéœ€è¦åŒæ­¥ {len(new_papers_data)} ç¯‡æ–°è®ºæ–‡")

        # æ‰¹é‡æ’å…¥æ–°è®ºæ–‡
        synced_count = 0
        if new_papers_data:
            for i in range(0, len(new_papers_data), batch_size):
                batch = new_papers_data[i : i + batch_size]
                try:
                    self.bitable_manager.batch_insert_records(table_id, batch)
                    synced_count += len(batch)
                    logger.info(f"âœ… æ‰¹é‡æ’å…¥ {len(batch)} æ¡è®°å½•")
                except Exception as e:
                    logger.error(f"âŒ æ‰¹é‡æ’å…¥å¤±è´¥: {e}")

        # è·å–æ€»è®°å½•æ•°
        total_count = len(existing_records) + synced_count

        # è·å–è¡¨æ ¼åç§°
        try:
            table_info = self.bitable_manager.get_table_info(table_id)
            table_name = table_info.get("name", f"{research_area}è®ºæ–‡è¡¨")
        except Exception:
            table_name = f"{research_area}è®ºæ–‡è¡¨"

        return {
            "synced_count": synced_count,
            "total_count": total_count,
            "table_name": table_name,
            "table_id": table_id,
            "new_papers": new_papers_original,  # è¿”å›æ–°å¢çš„åŸå§‹è®ºæ–‡æ•°æ®
        }

    def _format_paper_for_sync(self, paper: Any, research_area: str) -> Optional[Dict[str, Any]]:
        """æ ¼å¼åŒ–è®ºæ–‡æ•°æ®ç”¨äºåŒæ­¥"""
        try:
            if isinstance(paper, dict):
                # å­—å…¸æ ¼å¼
                arxiv_id = paper.get("arxiv_id", "")
                title = paper.get("title", "")
                authors = paper.get("authors", [])
                summary = paper.get("summary", "")
                categories = paper.get("categories", [])
                # ä¿®æ­£æ—¥æœŸå­—æ®µæ˜ å°„
                published = paper.get("published_date", paper.get("published", None))
                updated = paper.get("updated_date", paper.get("updated", None))
                relevance_score = paper.get("final_score", paper.get("relevance_score", 0.0))
                paper_url = paper.get("paper_url", f"http://arxiv.org/abs/{arxiv_id}")
                pdf_url = paper.get("pdf_url", f"http://arxiv.org/pdf/{arxiv_id}.pdf")
                # ä¿®æ­£å­—æ®µåæ˜ å°„
                matched_keywords = paper.get("matched_interests", paper.get("matched_keywords", []))
                required_keywords = paper.get("required_keyword_matches", paper.get("required_keywords_matched", []))
            else:
                # å¯¹è±¡æ ¼å¼
                arxiv_id = getattr(paper, "arxiv_id", "")
                title = getattr(paper, "title", "")
                authors = getattr(paper, "authors", [])
                summary = getattr(paper, "summary", "")
                categories = getattr(paper, "categories", [])
                published = getattr(paper, "published", None)
                updated = getattr(paper, "updated", None)
                relevance_score = getattr(paper, "final_score", getattr(paper, "relevance_score", 0.0))
                paper_url = getattr(paper, "paper_url", f"http://arxiv.org/abs/{arxiv_id}")
                pdf_url = getattr(paper, "pdf_url", f"http://arxiv.org/pdf/{arxiv_id}.pdf")
                matched_keywords = getattr(paper, "matched_keywords", [])
                required_keywords = getattr(paper, "required_keywords_matched", [])

            if not arxiv_id or not title:
                logger.warning(f"âš ï¸ è®ºæ–‡æ•°æ®ä¸å®Œæ•´ï¼Œè·³è¿‡: {arxiv_id}")
                return None

            # æ ¼å¼åŒ–æ•°æ®
            formatted_data = {
                "ArXiv ID": {"text": arxiv_id, "link": paper_url},
                "æ ‡é¢˜": title[:500],  # é™åˆ¶é•¿åº¦
                "ä½œè€…": [str(author)[:50] for author in (authors if isinstance(authors, list) else [str(authors)])][
                    :20
                ],
                "æ‘˜è¦": summary[:2000] if summary else "",  # é™åˆ¶æ‘˜è¦é•¿åº¦
                "åˆ†ç±»": [str(cat)[:30] for cat in (categories if isinstance(categories, list) else [str(categories)])][
                    :10
                ],
                "åŒ¹é…å…³é”®è¯": [str(kw)[:30] for kw in (matched_keywords if isinstance(matched_keywords, list) else [])][
                    :20
                ],
                "ç›¸å…³æ€§è¯„åˆ†": float(relevance_score) if relevance_score else 0.0,
                "ç ”ç©¶é¢†åŸŸ": [research_area],
                "PDFé“¾æ¥": {"text": "PDF", "link": pdf_url},
                "å¿…é¡»å…³é”®è¯åŒ¹é…": [
                    str(kw)[:30] for kw in (required_keywords if isinstance(required_keywords, list) else [])
                ][:10],
            }

            # å¤„ç†æ—¥æœŸå­—æ®µ
            if published:
                if isinstance(published, datetime):
                    formatted_data["å‘å¸ƒæ—¥æœŸ"] = int(published.timestamp() * 1000)
                elif isinstance(published, str):
                    try:
                        dt = datetime.fromisoformat(published.replace("Z", "+00:00"))
                        formatted_data["å‘å¸ƒæ—¥æœŸ"] = int(dt.timestamp() * 1000)
                    except ValueError:
                        pass

            if updated:
                if isinstance(updated, datetime):
                    formatted_data["æ›´æ–°æ—¥æœŸ"] = int(updated.timestamp() * 1000)
                elif isinstance(updated, str):
                    try:
                        dt = datetime.fromisoformat(updated.replace("Z", "+00:00"))
                        formatted_data["æ›´æ–°æ—¥æœŸ"] = int(dt.timestamp() * 1000)
                    except ValueError:
                        pass

            return formatted_data

        except Exception as e:
            logger.error(f"âŒ æ ¼å¼åŒ–è®ºæ–‡æ•°æ®å¤±è´¥: {e}")
            return None

    def sync_papers_to_feishu(
        self,
        papers: List[Dict[str, Any]],
        research_area: str = "general",
        user_name: str = "ç ”ç©¶å‘˜",
        sync_threshold: float = 0.0,
        batch_size: int = 20,
        enable_notification: bool = True,
    ) -> Dict[str, Any]:
        """åŒæ­¥è®ºæ–‡æ•°æ®åˆ°é£ä¹¦ï¼ˆå…¼å®¹æ—§æ¥å£ï¼‰

        Args:
            papers: è®ºæ–‡åˆ—è¡¨
            research_area: ç ”ç©¶é¢†åŸŸ
            user_name: ç”¨æˆ·åç§°
            sync_threshold: åŒæ­¥é˜ˆå€¼ï¼ˆç›¸å…³æ€§è¯„åˆ†ï¼‰
            batch_size: æ‰¹é‡åŒæ­¥å¤§å°
            enable_notification: æ˜¯å¦å¯ç”¨é€šçŸ¥

        Returns:
            åŒæ­¥ç»“æœç»Ÿè®¡
        """
        if not papers:
            logger.info("â„¹ï¸ æ²¡æœ‰è®ºæ–‡éœ€è¦åŒæ­¥")
            return {"synced_count": 0, "total_count": 0, "table_name": "", "table_id": ""}

        logger.info(f"ğŸ”„ å¼€å§‹åŒæ­¥ {len(papers)} ç¯‡è®ºæ–‡åˆ°é£ä¹¦...")

        # åœ¨åŒæ­¥å‰åˆ·æ–°tokenä»¥ç¡®ä¿æœ‰æ•ˆæ€§
        if not self.refresh_token_before_sync():
            logger.error("âŒ Tokenåˆ·æ–°å¤±è´¥ï¼ŒåŒæ­¥ç»ˆæ­¢")
            return {"synced_count": 0, "total_count": 0, "table_name": "", "table_id": "", "error": "Tokenåˆ·æ–°å¤±è´¥"}

        # åˆ›å»ºæˆ–è·å–è¡¨æ ¼
        table_display_name = f"{user_name.replace('ç ”ç©¶å‘˜', '')}è®ºæ–‡è¡¨"
        target_table_id = self.bitable_manager.find_table_by_name(table_display_name)

        if not target_table_id:
            logger.info(f"ğŸ†• åˆ›å»ºæ–°æ•°æ®è¡¨: {table_display_name}")
            table_result = self.bitable_manager.create_domain_papers_table(table_display_name, research_area)
            if table_result:
                target_table_id = table_result.get("table_id")
                logger.info(f"âœ… æ•°æ®è¡¨åˆ›å»ºæˆåŠŸï¼ŒID: {target_table_id}")
            else:
                logger.error("âŒ æ•°æ®è¡¨åˆ›å»ºå¤±è´¥")
                return {"synced_count": 0, "total_count": 0, "table_name": "", "table_id": ""}
        else:
            logger.info(f"âœ… æ‰¾åˆ°ç°æœ‰æ•°æ®è¡¨: {table_display_name} (ID: {target_table_id})")

        # ä½¿ç”¨æ–°çš„åŒæ­¥æ–¹æ³•
        sync_result = self._sync_papers_to_table(papers, target_table_id, research_area, batch_size)

        # å‘é€ç¾¤èŠé€šçŸ¥
        if enable_notification and sync_result.get("synced_count", 0) > 0:
            # è·å–æ–°å¢çš„è®ºæ–‡æ•°æ®ç”¨äºæ¨è
            new_papers = sync_result.get("new_papers", [])
            self._send_sync_notification(
                research_area=research_area,
                table_name=table_display_name,
                synced_count=sync_result.get("synced_count", 0),
                total_count=sync_result.get("total_count", 0),
                user_name=user_name,
                table_id=target_table_id,
                new_papers=new_papers,  # ä¼ é€’æ–°å¢çš„è®ºæ–‡æ•°æ®
            )

        return sync_result

    def _send_sync_notification(
        self,
        research_area: str,
        table_name: str,
        synced_count: int,
        total_count: int,
        user_name: str,
        table_id: str = None,
        new_papers: List[Dict[str, Any]] = None,
    ):
        """å‘é€åŒæ­¥é€šçŸ¥ï¼ˆå•è¡¨æ ¼æ¨¡å¼ï¼‰"""
        try:
            # æ„å»ºæ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            update_stats = {
                research_area: {
                    "new_count": synced_count,
                    "total_count": total_count,
                    "table_name": table_name,
                }
            }

            # æ„å»ºè¡¨æ ¼é“¾æ¥
            table_links = {}
            if table_id:
                table_link = self.chat_notifier.generate_table_link(table_id=table_id)
                if table_link:
                    table_links[research_area] = table_link

            # ä»æ–°å¢è®ºæ–‡ä¸­é€‰æ‹©è¯„åˆ†æœ€é«˜çš„è®ºæ–‡ä½œä¸ºæ¨è
            papers_by_field = {}
            if new_papers:
                # æŒ‰è¯„åˆ†æ’åºï¼Œé€‰æ‹©æœ€é«˜åˆ†çš„è®ºæ–‡
                sorted_papers = sorted(
                    new_papers, key=lambda p: p.get("relevance_score", p.get("final_score", 0)), reverse=True
                )
                papers_by_field[research_area] = sorted_papers

                logger.info(f"ğŸ“Š æ¨èè®ºæ–‡é€‰æ‹©ï¼šä» {len(new_papers)} ç¯‡æ–°è®ºæ–‡ä¸­é€‰æ‹©è¯„åˆ†æœ€é«˜çš„")
                if sorted_papers:
                    top_paper = sorted_papers[0]
                    top_score = top_paper.get("relevance_score", top_paper.get("final_score", 0))
                    logger.info(f"ğŸ† æœ€é«˜è¯„åˆ†è®ºæ–‡ï¼š{top_paper.get('title', 'æœªçŸ¥æ ‡é¢˜')[:50]}... (è¯„åˆ†: {top_score})")

            # å‘é€é€šçŸ¥
            self.chat_notifier.notify_paper_updates(update_stats, papers_by_field, table_links)  # ä¼ é€’æ–°å¢è®ºæ–‡ç”¨äºæ¨è

            logger.info("ğŸ“¢ ç¾¤èŠé€šçŸ¥å‘é€æˆåŠŸ")

        except Exception as e:
            logger.error(f"âŒ å‘é€ç¾¤èŠé€šçŸ¥å¤±è´¥: {e}")

    def sync_multiple_configs_to_feishu(
        self,
        config_results: List[Dict[str, Any]],
        enable_notification: bool = True,
    ) -> Dict[str, Any]:
        """æ‰¹é‡åŒæ­¥å¤šä¸ªé…ç½®çš„è®ºæ–‡åˆ°é£ä¹¦ï¼Œå‘é€æ±‡æ€»é€šçŸ¥

        Args:
            config_results: é…ç½®ç»“æœåˆ—è¡¨ï¼Œæ¯ä¸ªåŒ…å« {config_name, papers, research_area, user_name, ...}
            enable_notification: æ˜¯å¦å¯ç”¨é€šçŸ¥

        Returns:
            æ‰¹é‡åŒæ­¥ç»“æœç»Ÿè®¡
        """
        logger.info(f"ğŸš€ å¼€å§‹æ‰¹é‡åŒæ­¥ {len(config_results)} ä¸ªé…ç½®åˆ°é£ä¹¦...")

        all_sync_stats = {}
        all_table_links = {}
        all_new_papers_by_field = {}
        total_synced = 0
        total_papers = 0

        # é€ä¸ªå¤„ç†æ¯ä¸ªé…ç½®
        for config_result in config_results:
            config_name = config_result.get("config_name", "unknown")
            papers = config_result.get("papers", [])
            research_area = config_result.get("research_area", "general")
            user_name = config_result.get("user_name", "ç ”ç©¶å‘˜")

            if not papers:
                logger.info(f"â­ï¸ è·³è¿‡é…ç½® {config_name}ï¼šæ²¡æœ‰è®ºæ–‡")
                continue

            logger.info(f"ğŸ”„ å¤„ç†é…ç½® {config_name}ï¼š{len(papers)} ç¯‡è®ºæ–‡")

            # åŒæ­¥è¯¥é…ç½®çš„è®ºæ–‡
            sync_result = self.sync_papers_to_feishu(
                papers=papers,
                research_area=research_area,
                user_name=user_name,
                enable_notification=False,  # ç¦ç”¨å•ç‹¬é€šçŸ¥
            )

            if sync_result.get("synced_count", 0) > 0:
                # æ”¶é›†åŒæ­¥ç»“æœ
                all_sync_stats[research_area] = {
                    "table_id": sync_result.get("table_id"),
                    "table_name": sync_result.get("table_name", f"{research_area}è®ºæ–‡è¡¨"),
                    "new_count": sync_result.get("synced_count", 0),
                    "total_count": sync_result.get("total_count", 0),
                }

                # ç”Ÿæˆè¡¨æ ¼é“¾æ¥
                table_id = sync_result.get("table_id")
                if table_id:
                    table_link = self.chat_notifier.generate_table_link(table_id=table_id)
                    if table_link:
                        all_table_links[research_area] = table_link

                # æ”¶é›†æ–°å¢è®ºæ–‡ç”¨äºæ¨è
                new_papers = sync_result.get("new_papers", [])
                if new_papers:
                    all_new_papers_by_field[research_area] = new_papers

                total_synced += sync_result.get("synced_count", 0)
                total_papers += sync_result.get("total_count", 0)

            logger.info(f"âœ… é…ç½® {config_name} å®Œæˆï¼šæ–°å¢ {sync_result.get('synced_count', 0)} ç¯‡")

        logger.info(f"ğŸ“Š æ‰¹é‡åŒæ­¥å®Œæˆï¼š{len(all_sync_stats)} ä¸ªé¢†åŸŸï¼Œæ–°å¢ {total_synced} ç¯‡ï¼Œæ€»è®¡ {total_papers} ç¯‡")

        # å‘é€æ±‡æ€»é€šçŸ¥
        if enable_notification and total_synced > 0:
            logger.info("ğŸ“¢ å‘é€æ‰¹é‡åŒæ­¥æ±‡æ€»é€šçŸ¥...")
            self.chat_notifier.notify_paper_updates(all_sync_stats, all_new_papers_by_field, all_table_links)

        return {
            "synced_count": total_synced,
            "total_count": total_papers,
            "tables": all_sync_stats,
            "table_links": all_table_links,
            "processed_configs": len(config_results),
            "updated_areas": len(all_sync_stats),
        }


def create_sync_manager_from_config(cfg) -> SyncManager:
    """ä»é…ç½®åˆ›å»ºåŒæ­¥ç®¡ç†å™¨

    Args:
        cfg: Hydraé…ç½®å¯¹è±¡

    Returns:
        åŒæ­¥ç®¡ç†å™¨å®ä¾‹
    """
    from .config import FeishuConfig

    # åˆ›å»ºåŸºç¡€é…ç½®
    feishu_config = FeishuConfig.from_hydra_config(cfg)

    # åˆ›å»ºèŠå¤©é…ç½®
    feishu_cfg = cfg.get("feishu", {})
    chat_cfg = feishu_cfg.get("chat_notification", {})

    chat_config = ChatNotificationConfig(
        enabled=chat_cfg.get("enabled", True),
        notify_on_update=chat_cfg.get("notify_on_update", True),
        notify_on_new_papers=chat_cfg.get("notify_on_new_papers", True),
        min_papers_threshold=chat_cfg.get("min_papers_threshold", 1),
        max_recommended_papers=chat_cfg.get("max_recommended_papers", 1),
        message_template=chat_cfg.get("message_template", "default"),
    )

    return SyncManager(feishu_config, chat_config)
